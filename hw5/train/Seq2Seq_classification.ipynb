{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "from reader import readShortVideo\n",
    "from reader import getVideoList\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load features \n",
    "with open(\"../features/train_cut_features_350.pkl\", \"rb\") as f:\n",
    "    train_cut_features = pickle.load(f)\n",
    "with open(\"../features/train_cut_labels_350.pkl\", \"rb\") as f:\n",
    "    train_cut_labels = pickle.load(f)\n",
    "with open(\"../features/train_cut_lengths_350.pkl\", \"rb\") as f:\n",
    "    train_cut_lengths = pickle.load(f)\n",
    "    \n",
    "with open(\"../features/valid_cut_features_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_features = pickle.load(f)\n",
    "with open(\"../features/valid_cut_labels_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_labels = pickle.load(f)\n",
    "with open(\"../features/valid_cut_lengths_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_lengths = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.load(\"../models/RNN_FC_model.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, n_layers=2, dropout=0.1):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.hidden_size =  hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, self.hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=False,\n",
    "                           batch_first=True)\n",
    "        self.bn_0 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.fc_1 = nn.Linear(self.hidden_size, int(self.hidden_size/2))\n",
    "        self.bn_1 = nn.BatchNorm1d(int(self.hidden_size/2))\n",
    "        self.fc_2 = nn.Linear(int(self.hidden_size), 11)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, padded_sequence, input_lengths, hidden=None):\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(padded_sequence, \n",
    "                                                         input_lengths, \n",
    "                                                         batch_first=True)\n",
    "        outputs, (hn,cn) = self.lstm(packed, hidden) # output: (seq_len, batch, hidden*n_dir)\n",
    "        \n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        cut_frame_prediction = []\n",
    "        for i in range(outputs.size(0)):\n",
    "            category = self.fc_2(outputs[i])\n",
    "            cut_frame_prediction.append(category)\n",
    "\n",
    "        category = torch.stack(cut_frame_prediction)\n",
    "        return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_pad(input_feature, input_lengths, input_labels):\n",
    "    perm_index = np.argsort(input_lengths)[::-1]\n",
    "    input_feature =  [input_feature[i] for i in perm_index]\n",
    "    input_labels =  [input_labels[i] for i in perm_index]\n",
    "    input_lengths = sorted(input_lengths, reverse=True)\n",
    "    input_feature = nn.utils.rnn.pad_sequence(input_feature, batch_first=True)\n",
    "    return input_feature, input_labels, input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_batch_size = 32\n",
    "input_feature, input_labels, input_lengths = sort_pad(train_cut_features[:init_batch_size], \n",
    "                                                      train_cut_lengths[:init_batch_size],\n",
    "                                                      train_cut_labels[:init_batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_size = 1024*7*7\n",
    "with torch.no_grad():\n",
    "    model = seq2seq(feature_size,hidden_size=512).cuda()\n",
    "    model.eval()\n",
    "    init_batch_size = 32\n",
    "    \n",
    "    input_feature, input_labels, input_lengths = sort_pad(train_cut_features[:init_batch_size], \n",
    "                                                          train_cut_lengths[:init_batch_size],\n",
    "                                                          train_cut_labels[:init_batch_size])\n",
    "    output = model(input_feature.cuda(), \n",
    "               input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "    def forward(self, model_output, groundtruth, lengths):\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = 0\n",
    "        batch_size = model_output.size()[0]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            sample_length = lengths[i]\n",
    "            target = groundtruth[i].type(torch.LongTensor).cuda()\n",
    "            prediction = model_output[i][:sample_length]\n",
    "            partial_loss = criterion(prediction, target)\n",
    "            loss += partial_loss\n",
    "        loss = loss / batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "training loss 8.862705945968628\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 2\n",
      "training loss 7.444426536560059\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 3\n",
      "training loss 6.963853359222412\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 4\n",
      "training loss 6.72320294380188\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 5\n",
      "training loss 6.311319589614868\n",
      "0\n",
      "0\n",
      "14\n",
      "0\n",
      "59\n",
      "validation accuracy:  0.4754259501965924\n",
      "Epoch: 6\n",
      "training loss 6.050694704055786\n",
      "206\n",
      "0\n",
      "39\n",
      "85\n",
      "75\n",
      "validation accuracy:  0.49459370904325034\n",
      "Epoch: 7\n",
      "training loss 5.754278302192688\n",
      "869\n",
      "107\n",
      "183\n",
      "197\n",
      "97\n",
      "validation accuracy:  0.5371887287024901\n",
      "Epoch: 8\n",
      "training loss 5.453190445899963\n",
      "812\n",
      "102\n",
      "164\n",
      "190\n",
      "97\n",
      "validation accuracy:  0.5448885976408913\n",
      "Epoch: 9\n",
      "training loss 5.083771347999573\n",
      "855\n",
      "101\n",
      "170\n",
      "201\n",
      "96\n",
      "validation accuracy:  0.5447247706422018\n",
      "Epoch: 10\n",
      "training loss 4.7700968980789185\n",
      "827\n",
      "82\n",
      "146\n",
      "202\n",
      "93\n",
      "validation accuracy:  0.5504587155963303\n",
      "Epoch: 11\n",
      "training loss 4.498388409614563\n",
      "767\n",
      "4\n",
      "99\n",
      "192\n",
      "99\n",
      "validation accuracy:  0.5707732634338138\n",
      "Epoch: 12\n",
      "training loss 4.1024667620658875\n",
      "843\n",
      "39\n",
      "155\n",
      "214\n",
      "191\n",
      "validation accuracy:  0.5779816513761468\n",
      "Epoch: 13\n",
      "training loss 3.8429731130599976\n",
      "730\n",
      "7\n",
      "111\n",
      "166\n",
      "125\n",
      "validation accuracy:  0.5717562254259502\n",
      "Epoch: 14\n",
      "training loss 3.5350098609924316\n",
      "797\n",
      "43\n",
      "174\n",
      "185\n",
      "179\n",
      "validation accuracy:  0.5697903014416776\n",
      "Epoch: 15\n",
      "training loss 3.269717216491699\n",
      "920\n",
      "128\n",
      "294\n",
      "227\n",
      "302\n",
      "validation accuracy:  0.5704456094364351\n",
      "Epoch: 16\n",
      "training loss 3.0145612955093384\n",
      "791\n",
      "80\n",
      "215\n",
      "211\n",
      "221\n",
      "validation accuracy:  0.5730668414154653\n",
      "Epoch: 17\n",
      "training loss 2.843669831752777\n",
      "582\n",
      "52\n",
      "151\n",
      "185\n",
      "149\n",
      "validation accuracy:  0.5542267365661862\n",
      "Epoch: 18\n",
      "training loss 2.620392918586731\n",
      "838\n",
      "124\n",
      "275\n",
      "237\n",
      "254\n",
      "validation accuracy:  0.5668414154652687\n",
      "Epoch: 19\n",
      "training loss 2.399291157722473\n",
      "954\n",
      "151\n",
      "332\n",
      "270\n",
      "323\n",
      "validation accuracy:  0.5666775884665793\n",
      "Epoch: 20\n",
      "training loss 2.2586407363414764\n",
      "797\n",
      "114\n",
      "264\n",
      "225\n",
      "237\n",
      "validation accuracy:  0.5670052424639581\n"
     ]
    }
   ],
   "source": [
    "feature_size = 1024*7*7\n",
    "model = seq2seq(feature_size,hidden_size=512,dropout=0.5, n_layers=2).cuda()\n",
    "# model.load_state_dict(weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "BATCH_SIZE = 32\n",
    "loss_function = Loss().cuda()\n",
    "max_accuracy = 0\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    CE_loss = 0.0\n",
    "    total_length = len(train_cut_features)\n",
    "    # shuffle\n",
    "    perm_index = np.random.permutation(total_length)\n",
    "    train_X_sfl = [train_cut_features[i] for i in perm_index]\n",
    "    train_y_sfl = [train_cut_labels[i] for i in perm_index]\n",
    "    train_lengths_sfl = np.array(train_cut_lengths)[perm_index]\n",
    "    # construct training batch\n",
    "    for index in range(0,total_length ,BATCH_SIZE):\n",
    "        if index+BATCH_SIZE > total_length:\n",
    "            break\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        input_X = train_X_sfl[index:index+BATCH_SIZE]\n",
    "        input_y = train_y_sfl[index:index+BATCH_SIZE]\n",
    "        input_lengths = train_lengths_sfl[index:index+BATCH_SIZE]\n",
    "        input_X, input_y, input_lengths = sort_pad(input_X, input_lengths, input_y)\n",
    "#         input_y = torch.stack([j for i in input_y for j in i]).type(torch.LongTensor)\n",
    "        # use GPU\n",
    "#         input_X = torch.nn.utils.rnn.pad_sequence(input_X).cuda()\n",
    "        # forward + backward + optimize\n",
    "        output = model(input_X.cuda(), input_lengths)\n",
    "        # compute loss for each sample in training data\n",
    "        loss = loss_function(output, input_y,input_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        CE_loss += loss.cpu().data.numpy()\n",
    "    print(\"training loss\",CE_loss)\n",
    "    \n",
    "    # validation\n",
    "    same_difference = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_output = []\n",
    "        valid_y_list = []\n",
    "        for valid_X, valid_y, valid_lengths in zip(valid_cut_features, valid_cut_labels, \n",
    "                                                   valid_cut_lengths):\n",
    "#             input_X, input_y, input_lengths = sort_pad([valid_X], [valid_lengths],\n",
    "#                                                   [valid_y])\n",
    "#             input_y = torch.stack([j for i in input_y for j in i]).type(torch.LongTensor)\n",
    "            input_valid_X = valid_X.unsqueeze(0)\n",
    "            output = model(input_valid_X.cuda(), [valid_lengths])\n",
    "            prediction = torch.argmax(torch.squeeze(output.cpu()),1).data.numpy()\n",
    "            print(sum(prediction!=0))\n",
    "            valid_gt = np.array(valid_y)\n",
    "            same_difference.append(prediction==valid_gt)\n",
    "#         valid_output = np.vstack(valid_output)\n",
    "#         valid_y_list = [j for i in valid_y_list for j in i]\n",
    "#         output_label = np.argmax(valid_output,1)\n",
    "#         same_difference = (output_label == valid_y_list)\n",
    "        total = []\n",
    "        for i in same_difference:\n",
    "            total+=list(i)\n",
    "        accuracy = np.mean(total)\n",
    "        print(\"validation accuracy: \",accuracy)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"../models/RNN_seq2seq_model.pkt\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 1024*7*7\n",
    "model = seq2seq(feature_size,hidden_size=512,dropout=0.5, n_layers=2).cuda()\n",
    "model.load_state_dict(torch.load(\"../models/RNN_seq2seq_model.pkt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    valid_output = []\n",
    "    for valid_X, valid_lengths in zip(valid_cut_features, valid_cut_lengths):\n",
    "        input_valid_X = valid_X.unsqueeze(0)\n",
    "        output = model(input_valid_X.cuda(), [valid_lengths])\n",
    "        prediction = torch.argmax(torch.squeeze(output.cpu()),1).data.numpy()\n",
    "        valid_output.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_dir_name = sorted(listdir(\"../HW5_data/FullLengthVideos/videos/valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OP01-R03-BaconAndEggs',\n",
       " 'OP02-R04-ContinentalBreakfast',\n",
       " 'OP03-R02-TurkeySandwich',\n",
       " 'OP05-R07-Pizza',\n",
       " 'OP06-R05-Cheeseburger']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder = \"../output/\"\n",
    "for i in range(len(valid_dir_name)):\n",
    "    with open(os.path.join(output_folder, valid_dir_name[i]+'.txt'), \"w\") as f:\n",
    "        for j, pred in enumerate(valid_output[i]):\n",
    "            f.write(str(pred))\n",
    "            if j != len(valid_output[i])-1:\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAADuCAYAAABVsAiGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwBAKJwAAAEP8H+ac3pUFNXKjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: https://matplotlib.org/2.0.2/examples/api/colorbar_only.html\n",
    "video_num = 4\n",
    "test = valid_output[video_num][544:844]\n",
    "answer = valid_cut_labels[video_num][544:844]\n",
    "plt.figure(figsize=(16,4))\n",
    "ax = plt.subplot(211)\n",
    "color_index = np.array([ 38,  2,  9,  6,  8, 10, 12, 14, 16, 18, 20, 22])\n",
    "colors = [\"wheat\", \"turqoise\", \"teal\", \"sienna\", \"salmon\", \"orange\", \n",
    "          \"lightblue\", \"lavender\", \"gold\", \"darkblue\", \"azure\"]\n",
    "# colors = np.array(list((matplotlib.colors.CSS4_COLORS.keys())))[color_index]\n",
    "cmap = matplotlib.colors.ListedColormap([colors[idx] for idx in test])\n",
    "bounds = [i for i in range(len(test))]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cb1 = matplotlib.colorbar.ColorbarBase(ax, cmap=cmap,\n",
    "                                       norm=norm,\n",
    "                                       boundaries=bounds,\n",
    "                                       spacing='proportional',\n",
    "                                       orientation='horizontal',\n",
    "                                       ticks= range(544,844))\n",
    "ax.set_ylabel('Prediction')\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "cmap = matplotlib.colors.ListedColormap([colors[idx] for idx in answer])\n",
    "bounds = [i for i in range(len(test))]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cb2 = matplotlib.colorbar.ColorbarBase(ax2, cmap=cmap,\n",
    "                                       norm=norm,\n",
    "                                       boundaries=bounds,\n",
    "                                       spacing='proportional',\n",
    "                                       orientation='horizontal',\n",
    "                                       ticks= list(range(544,844)))\n",
    "\n",
    "\n",
    "ax2.set_ylabel('GroundTruth')\n",
    "\n",
    "plt.savefig(\"temporal_action_segmentation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
