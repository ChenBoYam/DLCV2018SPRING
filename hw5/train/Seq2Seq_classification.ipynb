{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "from reader import readShortVideo\n",
    "from reader import getVideoList\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load features \n",
    "with open(\"../features/train_cut_features_350.pkl\", \"rb\") as f:\n",
    "    train_cut_features = pickle.load(f)\n",
    "with open(\"../features/train_cut_labels_350.pkl\", \"rb\") as f:\n",
    "    train_cut_labels = pickle.load(f)\n",
    "with open(\"../features/train_cut_lengths_350.pkl\", \"rb\") as f:\n",
    "    train_cut_lengths = pickle.load(f)\n",
    "    \n",
    "with open(\"../features/valid_cut_features_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_features = pickle.load(f)\n",
    "with open(\"../features/valid_cut_labels_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_labels = pickle.load(f)\n",
    "with open(\"../features/valid_cut_lengths_no_cut.pkl\", \"rb\") as f:\n",
    "    valid_cut_lengths = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.load(\"../models/RNN_FC_model.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, n_layers=2, dropout=0.1):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.hidden_size =  hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, self.hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=False,\n",
    "                           batch_first=True)\n",
    "        self.bn_0 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.fc_1 = nn.Linear(self.hidden_size, int(self.hidden_size/2))\n",
    "        self.bn_1 = nn.BatchNorm1d(int(self.hidden_size/2))\n",
    "        self.fc_2 = nn.Linear(int(self.hidden_size), 11)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, padded_sequence, input_lengths, hidden=None):\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(padded_sequence, \n",
    "                                                         input_lengths, \n",
    "                                                         batch_first=True)\n",
    "        outputs, (hn,cn) = self.lstm(packed, hidden) # output: (seq_len, batch, hidden*n_dir)\n",
    "        \n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        cut_frame_prediction = []\n",
    "        for i in range(outputs.size(0)):\n",
    "            category = self.fc_2(outputs[i])\n",
    "            cut_frame_prediction.append(category)\n",
    "\n",
    "        category = torch.stack(cut_frame_prediction)\n",
    "        return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_pad(input_feature, input_lengths, input_labels):\n",
    "    perm_index = np.argsort(input_lengths)[::-1]\n",
    "    input_feature =  [input_feature[i] for i in perm_index]\n",
    "    input_labels =  [input_labels[i] for i in perm_index]\n",
    "    input_lengths = sorted(input_lengths, reverse=True)\n",
    "    input_feature = nn.utils.rnn.pad_sequence(input_feature, batch_first=True)\n",
    "    return input_feature, input_labels, input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_batch_size = 32\n",
    "input_feature, input_labels, input_lengths = sort_pad(train_cut_features[:init_batch_size], \n",
    "                                                      train_cut_lengths[:init_batch_size],\n",
    "                                                      train_cut_labels[:init_batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_size = 1024*7*7\n",
    "with torch.no_grad():\n",
    "    model = seq2seq(feature_size,hidden_size=512).cuda()\n",
    "    model.eval()\n",
    "    init_batch_size = 32\n",
    "    \n",
    "    input_feature, input_labels, input_lengths = sort_pad(train_cut_features[:init_batch_size], \n",
    "                                                          train_cut_lengths[:init_batch_size],\n",
    "                                                          train_cut_labels[:init_batch_size])\n",
    "    output = model(input_feature.cuda(), \n",
    "               input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "    def forward(self, model_output, groundtruth, lengths):\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = 0\n",
    "        batch_size = model_output.size()[0]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            sample_length = lengths[i]\n",
    "            target = groundtruth[i].type(torch.LongTensor).cuda()\n",
    "            prediction = model_output[i][:sample_length]\n",
    "            partial_loss = criterion(prediction, target)\n",
    "            loss += partial_loss\n",
    "        loss = loss / batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "training loss 8.862705945968628\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 2\n",
      "training loss 7.444426536560059\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 3\n",
      "training loss 6.963853359222412\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 4\n",
      "training loss 6.72320294380188\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "validation accuracy:  0.4660878112712975\n",
      "Epoch: 5\n",
      "training loss 6.311319589614868\n",
      "0\n",
      "0\n",
      "14\n",
      "0\n",
      "59\n",
      "validation accuracy:  0.4754259501965924\n",
      "Epoch: 6\n",
      "training loss 6.050694704055786\n",
      "206\n",
      "0\n",
      "39\n",
      "85\n",
      "75\n",
      "validation accuracy:  0.49459370904325034\n",
      "Epoch: 7\n",
      "training loss 5.754278302192688\n",
      "869\n",
      "107\n",
      "183\n",
      "197\n",
      "97\n",
      "validation accuracy:  0.5371887287024901\n",
      "Epoch: 8\n",
      "training loss 5.453190445899963\n",
      "812\n",
      "102\n",
      "164\n",
      "190\n",
      "97\n",
      "validation accuracy:  0.5448885976408913\n",
      "Epoch: 9\n",
      "training loss 5.083771347999573\n",
      "855\n",
      "101\n",
      "170\n",
      "201\n",
      "96\n",
      "validation accuracy:  0.5447247706422018\n",
      "Epoch: 10\n",
      "training loss 4.7700968980789185\n",
      "827\n",
      "82\n",
      "146\n",
      "202\n",
      "93\n",
      "validation accuracy:  0.5504587155963303\n",
      "Epoch: 11\n",
      "training loss 4.498388409614563\n",
      "767\n",
      "4\n",
      "99\n",
      "192\n",
      "99\n",
      "validation accuracy:  0.5707732634338138\n",
      "Epoch: 12\n",
      "training loss 4.1024667620658875\n",
      "843\n",
      "39\n",
      "155\n",
      "214\n",
      "191\n",
      "validation accuracy:  0.5779816513761468\n",
      "Epoch: 13\n",
      "training loss 3.8429731130599976\n",
      "730\n",
      "7\n",
      "111\n",
      "166\n",
      "125\n",
      "validation accuracy:  0.5717562254259502\n",
      "Epoch: 14\n",
      "training loss 3.5350098609924316\n",
      "797\n",
      "43\n",
      "174\n",
      "185\n",
      "179\n",
      "validation accuracy:  0.5697903014416776\n",
      "Epoch: 15\n",
      "training loss 3.269717216491699\n",
      "920\n",
      "128\n",
      "294\n",
      "227\n",
      "302\n",
      "validation accuracy:  0.5704456094364351\n",
      "Epoch: 16\n",
      "training loss 3.0145612955093384\n",
      "791\n",
      "80\n",
      "215\n",
      "211\n",
      "221\n",
      "validation accuracy:  0.5730668414154653\n",
      "Epoch: 17\n",
      "training loss 2.843669831752777\n",
      "582\n",
      "52\n",
      "151\n",
      "185\n",
      "149\n",
      "validation accuracy:  0.5542267365661862\n",
      "Epoch: 18\n",
      "training loss 2.620392918586731\n",
      "838\n",
      "124\n",
      "275\n",
      "237\n",
      "254\n",
      "validation accuracy:  0.5668414154652687\n",
      "Epoch: 19\n",
      "training loss 2.399291157722473\n",
      "954\n",
      "151\n",
      "332\n",
      "270\n",
      "323\n",
      "validation accuracy:  0.5666775884665793\n",
      "Epoch: 20\n",
      "training loss 2.2586407363414764\n",
      "797\n",
      "114\n",
      "264\n",
      "225\n",
      "237\n",
      "validation accuracy:  0.5670052424639581\n"
     ]
    }
   ],
   "source": [
    "feature_size = 1024*7*7\n",
    "model = seq2seq(feature_size,hidden_size=512,dropout=0.5, n_layers=2).cuda()\n",
    "# model.load_state_dict(weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "BATCH_SIZE = 32\n",
    "loss_function = Loss().cuda()\n",
    "max_accuracy = 0\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    CE_loss = 0.0\n",
    "    total_length = len(train_cut_features)\n",
    "    # shuffle\n",
    "    perm_index = np.random.permutation(total_length)\n",
    "    train_X_sfl = [train_cut_features[i] for i in perm_index]\n",
    "    train_y_sfl = [train_cut_labels[i] for i in perm_index]\n",
    "    train_lengths_sfl = np.array(train_cut_lengths)[perm_index]\n",
    "    # construct training batch\n",
    "    for index in range(0,total_length ,BATCH_SIZE):\n",
    "        if index+BATCH_SIZE > total_length:\n",
    "            break\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        input_X = train_X_sfl[index:index+BATCH_SIZE]\n",
    "        input_y = train_y_sfl[index:index+BATCH_SIZE]\n",
    "        input_lengths = train_lengths_sfl[index:index+BATCH_SIZE]\n",
    "        input_X, input_y, input_lengths = sort_pad(input_X, input_lengths, input_y)\n",
    "#         input_y = torch.stack([j for i in input_y for j in i]).type(torch.LongTensor)\n",
    "        # use GPU\n",
    "#         input_X = torch.nn.utils.rnn.pad_sequence(input_X).cuda()\n",
    "        # forward + backward + optimize\n",
    "        output = model(input_X.cuda(), input_lengths)\n",
    "        # compute loss for each sample in training data\n",
    "        loss = loss_function(output, input_y,input_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        CE_loss += loss.cpu().data.numpy()\n",
    "    print(\"training loss\",CE_loss)\n",
    "    \n",
    "    # validation\n",
    "    same_difference = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_output = []\n",
    "        valid_y_list = []\n",
    "        for valid_X, valid_y, valid_lengths in zip(valid_cut_features, valid_cut_labels, \n",
    "                                                   valid_cut_lengths):\n",
    "#             input_X, input_y, input_lengths = sort_pad([valid_X], [valid_lengths],\n",
    "#                                                   [valid_y])\n",
    "#             input_y = torch.stack([j for i in input_y for j in i]).type(torch.LongTensor)\n",
    "            input_valid_X = valid_X.unsqueeze(0)\n",
    "            output = model(input_valid_X.cuda(), [valid_lengths])\n",
    "            prediction = torch.argmax(torch.squeeze(output.cpu()),1).data.numpy()\n",
    "            print(sum(prediction!=0))\n",
    "            valid_gt = np.array(valid_y)\n",
    "            same_difference.append(prediction==valid_gt)\n",
    "#         valid_output = np.vstack(valid_output)\n",
    "#         valid_y_list = [j for i in valid_y_list for j in i]\n",
    "#         output_label = np.argmax(valid_output,1)\n",
    "#         same_difference = (output_label == valid_y_list)\n",
    "        total = []\n",
    "        for i in same_difference:\n",
    "            total+=list(i)\n",
    "        accuracy = np.mean(total)\n",
    "        print(\"validation accuracy: \",accuracy)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"../models/RNN_seq2seq_model.pkt\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_output = []\n",
    "        valid_y_list = []\n",
    "        for valid_X, valid_y, valid_lengths in zip(valid_cut_features, valid_cut_labels, \n",
    "                                                   valid_cut_lengths):\n",
    "#             input_X, input_y, input_lengths = sort_pad([valid_X], [valid_lengths],\n",
    "#                                                   [valid_y])\n",
    "#             input_y = torch.stack([j for i in input_y for j in i]).type(torch.LongTensor)\n",
    "            input_valid_X = valid_X.unsqueeze(0)\n",
    "            output = model(input_valid_X.cuda(), [valid_lengths])\n",
    "            prediction = torch.argmax(torch.squeeze(output.cpu()),1).data.numpy()\n",
    "            valid_output.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_dir_name = listdir(\"/home/thtang/DLCV2018SPRING/hw5/HW5_data/FullLengthVideos/videos/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OP06-R05-Cheeseburger',\n",
       " 'OP02-R04-ContinentalBreakfast',\n",
       " 'OP01-R03-BaconAndEggs',\n",
       " 'OP05-R07-Pizza',\n",
       " 'OP03-R02-TurkeySandwich']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder = \"../output/\"\n",
    "for i in range(len(valid_dir_name)):\n",
    "    with open(os.path.join(output_folder, valid_dir_name[i]+'.txt'), \"w\") as f:\n",
    "        for j, pred in enumerate(valid_output[i]):\n",
    "            f.write(str(pred))\n",
    "            if j != len(valid_output[i])-1:\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAADuCAYAAABVsAiGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: https://matplotlib.org/2.0.2/examples/api/colorbar_only.html\n",
    "video_num = 4\n",
    "test = valid_output[video_num][544:844]\n",
    "answer = valid_cut_labels[video_num][544:844]\n",
    "plt.figure(figsize=(16,4))\n",
    "ax = plt.subplot(211)\n",
    "colors = ['w', 'g', 'r', 'c', 'm', 'y', 'k', 'b', 'C0', 'C1', 'C2']\n",
    "cmap = matplotlib.colors.ListedColormap([colors[idx] for idx in test])\n",
    "bounds = [i for i in range(len(test))]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cb1 = matplotlib.colorbar.ColorbarBase(ax, cmap=cmap,\n",
    "                                       norm=norm,\n",
    "                                       boundaries=bounds,\n",
    "                                       spacing='proportional',\n",
    "                                       orientation='horizontal',\n",
    "                                       ticks= range(544,844))\n",
    "ax.set_ylabel('Prediction')\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "colors = ['w', 'g', 'r', 'c', 'm', 'y', 'k', 'b', 'C0', 'C1', 'C2']\n",
    "cmap = matplotlib.colors.ListedColormap([colors[idx] for idx in answer])\n",
    "bounds = [i for i in range(len(test))]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cb2 = matplotlib.colorbar.ColorbarBase(ax2, cmap=cmap,\n",
    "                                       norm=norm,\n",
    "                                       boundaries=bounds,\n",
    "                                       spacing='proportional',\n",
    "                                       orientation='horizontal',\n",
    "                                       ticks= list(range(544,844)))\n",
    "\n",
    "\n",
    "ax2.set_ylabel('GroundTruth')\n",
    "\n",
    "plt.savefig(\"temporal_action_segmentation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
