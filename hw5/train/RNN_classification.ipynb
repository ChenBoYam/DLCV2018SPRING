{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "from reader import readShortVideo\n",
    "from reader import getVideoList\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read pre-defined feature and train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../train_features_d12.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)\n",
    "with open(\"../valid_features_d12.pkl\", \"rb\") as f:\n",
    "    valid_features = pickle.load(f)\n",
    "    \n",
    "with open(\"../train_y.pkl\", \"rb\") as f:\n",
    "    train_y = pickle.load(f)\n",
    "with open(\"../valid_y.pkl\", \"rb\") as f:\n",
    "    valid_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, n_layers=2, dropout=0.5):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size =  hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, self.hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=False)\n",
    "        self.bn_0 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.fc_1 = nn.Linear(self.hidden_size, int(self.hidden_size/2))\n",
    "        self.bn_1 = nn.BatchNorm1d(int(self.hidden_size/2))\n",
    "        self.fc_2 = nn.Linear(int(self.hidden_size), 11)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, padded_sequence, input_lengths, hidden=None):\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(padded_sequence, input_lengths)\n",
    "        outputs, (hn,cn) = self.lstm(packed, hidden) # output: (seq_len, batch, hidden*n_dir)\n",
    "#         outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "#         outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs (1, batch, hidden)\n",
    "        outputs = self.bn_0(hn[-1])\n",
    "        outputs = self.softmax(self.fc_2(outputs))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_batch_padding(train_X_batch, train_y_batch, test = False):\n",
    "    if test==True:\n",
    "        padded_sequence = nn.utils.rnn.pad_sequence(train_X_batch)\n",
    "        label = torch.LongTensor(train_y_batch)\n",
    "        length = [len(train_X_batch[0])]\n",
    "    else:\n",
    "        length = [len(x) for x in train_X_batch]\n",
    "        perm_index = np.argsort(length)[::-1]\n",
    "\n",
    "        # sort by sequence length\n",
    "        train_X_batch = [train_X_batch[i] for i in perm_index]\n",
    "        length = [len(x) for x in train_X_batch]\n",
    "        padded_sequence = nn.utils.rnn.pad_sequence(train_X_batch)\n",
    "        label = torch.LongTensor(np.array(train_y_batch)[perm_index])\n",
    "    return padded_sequence, label, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_valid_X, input_valid_y, valid_lengths = single_batch_padding([valid_features[0]], [valid_y[0]],\n",
    "                                                                  test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "training loss 116.47475147247314\n",
      "validation accuracy:  0.28433268858800775\n",
      "Epoch: 2\n",
      "training loss 108.52313160896301\n",
      "validation accuracy:  0.3849129593810445\n",
      "Epoch: 3\n",
      "training loss 103.10326600074768\n",
      "validation accuracy:  0.44874274661508706\n",
      "Epoch: 4\n",
      "training loss 99.2244381904602\n",
      "validation accuracy:  0.4835589941972921\n",
      "Epoch: 5\n",
      "training loss 95.94136488437653\n",
      "validation accuracy:  0.4738878143133462\n",
      "Epoch: 6\n",
      "training loss 93.1365247964859\n",
      "validation accuracy:  0.5067698259187621\n",
      "Epoch: 7\n",
      "training loss 91.02155685424805\n",
      "validation accuracy:  0.49709864603481624\n",
      "Epoch: 8\n",
      "training loss 89.38884377479553\n",
      "validation accuracy:  0.4990328820116054\n",
      "Epoch: 9\n",
      "training loss 87.75367951393127\n",
      "validation accuracy:  0.5183752417794971\n",
      "Epoch: 10\n",
      "training loss 86.91279792785645\n",
      "validation accuracy:  0.5183752417794971\n",
      "Epoch: 11\n",
      "training loss 86.06727576255798\n",
      "validation accuracy:  0.5067698259187621\n",
      "Epoch: 12\n",
      "training loss 85.13175427913666\n",
      "validation accuracy:  0.5087040618955513\n",
      "Epoch: 13\n",
      "training loss 84.02549648284912\n",
      "validation accuracy:  0.5067698259187621\n",
      "Epoch: 14\n",
      "training loss 83.53977656364441\n",
      "validation accuracy:  0.5261121856866537\n",
      "Epoch: 15\n",
      "training loss 82.9427205324173\n",
      "validation accuracy:  0.48549323017408125\n",
      "Epoch: 16\n",
      "training loss 82.82999515533447\n",
      "validation accuracy:  0.47775628626692457\n",
      "Epoch: 17\n",
      "training loss 82.50444710254669\n",
      "validation accuracy:  0.4990328820116054\n",
      "Epoch: 18\n",
      "training loss 82.16576445102692\n",
      "validation accuracy:  0.5125725338491296\n",
      "Epoch: 19\n",
      "training loss 81.67050862312317\n",
      "validation accuracy:  0.5164410058027079\n",
      "Epoch: 20\n",
      "training loss 81.50236129760742\n",
      "validation accuracy:  0.5067698259187621\n"
     ]
    }
   ],
   "source": [
    "feature_size = 1024*7*7\n",
    "model = rnn = GRU(feature_size,hidden_size=512).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "BATCH_SIZE = 64\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "max_accuracy = 0\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    CE_loss = 0.0\n",
    "    total_length = len(train_features)\n",
    "    # shuffle\n",
    "    perm_index = np.random.permutation(len(train_features))\n",
    "    train_X_sfl = [ train_features[i] for i in perm_index]\n",
    "    train_y_sfl = np.array(train_y)[perm_index]\n",
    "    # construct training batch\n",
    "    for index in range(0,total_length ,BATCH_SIZE):\n",
    "        if index+BATCH_SIZE > total_length:\n",
    "            break\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        input_X = train_X_sfl[index:index+BATCH_SIZE]\n",
    "        input_y = train_y_sfl[index:index+BATCH_SIZE]\n",
    "        \n",
    "        # pad the sequence\n",
    "        input_X, input_y, length = single_batch_padding(input_X, input_y)\n",
    "        \n",
    "        # use GPU\n",
    "        input_X = input_X.cuda()\n",
    "        # forward + backward + optimize\n",
    "        output = model(input_X, length)\n",
    "        loss = loss_function(output, input_y.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        CE_loss += loss.cpu().data.numpy()\n",
    "    print(\"training loss\",CE_loss)\n",
    "    \n",
    "    # validation\n",
    "    same_difference = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(len(valid_y)):\n",
    "            input_valid_X, input_valid_y, valid_lengths = single_batch_padding([valid_features[i]], \n",
    "                                                                               [valid_y[i]],\n",
    "                                                                               test=True)\n",
    "            output = model(input_valid_X.cuda(),valid_lengths)\n",
    "            output_label = torch.argmax(output,1).cpu().data\n",
    "            same_difference.append((output_label == input_valid_y).numpy())\n",
    "        accuracy = np.mean(same_difference)\n",
    "        print(\"validation accuracy: \",accuracy)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"../models/RNN_FC_model.pkt\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先加 hidden dimension\n",
    "# 加 fc layer\n",
    "# 調 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
