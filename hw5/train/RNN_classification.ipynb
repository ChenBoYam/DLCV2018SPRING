{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "from reader import readShortVideo\n",
    "from reader import getVideoList\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read pre-defined feature and train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../train_features_d12.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)\n",
    "with open(\"../valid_features_d12.pkl\", \"rb\") as f:\n",
    "    valid_features = pickle.load(f)\n",
    "    \n",
    "with open(\"../train_y.pkl\", \"rb\") as f:\n",
    "    train_y = pickle.load(f)\n",
    "with open(\"../valid_y.pkl\", \"rb\") as f:\n",
    "    valid_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, n_layers=2, dropout=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size =  hidden_size\n",
    "        self.gru = nn.GRU(input_size, self.hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=False)\n",
    "        self.bn_0 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.fc_1 = nn.Linear(self.hidden_size, int(self.hidden_size/2))\n",
    "        self.bn_1 = nn.BatchNorm1d(int(self.hidden_size/2))\n",
    "        self.fc_2 = nn.Linear(int(self.hidden_size), 11)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, padded_sequence, input_lengths, hidden=None):\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(padded_sequence, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden) # output: (seq_len, batch, hidden*n_dir)\n",
    "#         outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "#         outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs (1, batch, hidden)\n",
    "        outputs = self.bn_0(hidden[-1])\n",
    "#         print(hidden.size())\n",
    "        outputs = self.softmax(self.fc_2(outputs))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_batch_padding(train_X_batch, train_y_batch, test = False):\n",
    "    if test==True:\n",
    "        padded_sequence = nn.utils.rnn.pad_sequence(train_X_batch)\n",
    "        label = torch.LongTensor(train_y_batch)\n",
    "        length = [len(train_X_batch[0])]\n",
    "    else:\n",
    "        length = [len(x) for x in train_X_batch]\n",
    "        perm_index = np.argsort(length)[::-1]\n",
    "\n",
    "        # sort by sequence length\n",
    "        train_X_batch = [train_X_batch[i] for i in perm_index]\n",
    "        length = [len(x) for x in train_X_batch]\n",
    "        padded_sequence = nn.utils.rnn.pad_sequence(train_X_batch)\n",
    "        label = torch.LongTensor(np.array(train_y_batch)[perm_index])\n",
    "    return padded_sequence, label, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_valid_X, input_valid_y, valid_lengths = single_batch_padding([valid_features[0]], [valid_y[0]],\n",
    "                                                                  test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "training loss 115.2590401172638\n",
      "validation accuracy:  0.30754352030947774\n",
      "Epoch: 2\n",
      "training loss 106.55433082580566\n",
      "validation accuracy:  0.38878143133462284\n",
      "Epoch: 3\n",
      "training loss 100.63670098781586\n",
      "validation accuracy:  0.4758220502901354\n",
      "Epoch: 4\n",
      "training loss 94.97878885269165\n",
      "validation accuracy:  0.4584139264990329\n",
      "Epoch: 5\n",
      "training loss 90.07201898097992\n",
      "validation accuracy:  0.46421663442940037\n",
      "Epoch: 6\n",
      "training loss 86.38283801078796\n",
      "validation accuracy:  0.4951644100580271\n",
      "Epoch: 7\n",
      "training loss 84.02891755104065\n",
      "validation accuracy:  0.47195357833655704\n",
      "Epoch: 8\n",
      "training loss 82.30059111118317\n",
      "validation accuracy:  0.4506769825918762\n",
      "Epoch: 9\n",
      "training loss 81.10160660743713\n",
      "validation accuracy:  0.4584139264990329\n",
      "Epoch: 10\n",
      "training loss 80.1844789981842\n",
      "validation accuracy:  0.4584139264990329\n",
      "Epoch: 11\n",
      "training loss 79.35345506668091\n",
      "validation accuracy:  0.4796905222437137\n",
      "Epoch: 12\n",
      "training loss 78.8776183128357\n",
      "validation accuracy:  0.4448742746615087\n",
      "Epoch: 13\n",
      "training loss 78.57012557983398\n",
      "validation accuracy:  0.4197292069632495\n",
      "Epoch: 14\n",
      "training loss 78.20301568508148\n",
      "validation accuracy:  0.4526112185686654\n",
      "Epoch: 15\n",
      "training loss 78.00245976448059\n",
      "validation accuracy:  0.425531914893617\n"
     ]
    }
   ],
   "source": [
    "feature_size = 1024*7*7\n",
    "model = rnn = GRU(feature_size,hidden_size=512).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "BATCH_SIZE = 64\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "max_accuracy = 0\n",
    "model.train()\n",
    "for epoch in range(15):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    CE_loss = 0.0\n",
    "    total_length = len(train_features)\n",
    "    # shuffle\n",
    "    perm_index = np.random.permutation(len(train_features))\n",
    "    train_X_sfl = [ train_features[i] for i in perm_index]\n",
    "    train_y_sfl = np.array(train_y)[perm_index]\n",
    "    # construct training batch\n",
    "    for index in range(0,total_length ,BATCH_SIZE):\n",
    "        if index+BATCH_SIZE > total_length:\n",
    "            break\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        input_X = train_X_sfl[index:index+BATCH_SIZE]\n",
    "        input_y = train_y_sfl[index:index+BATCH_SIZE]\n",
    "        \n",
    "        # pad the sequence\n",
    "        input_X, input_y, length = single_batch_padding(input_X, input_y)\n",
    "        \n",
    "        # use GPU\n",
    "        input_X = input_X.cuda()\n",
    "        # forward + backward + optimize\n",
    "        output = model(input_X, length)\n",
    "        loss = loss_function(output, input_y.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        CE_loss += loss.cpu().data.numpy()\n",
    "    print(\"training loss\",CE_loss)\n",
    "    \n",
    "    # validation\n",
    "    same_difference = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(len(valid_y)):\n",
    "            input_valid_X, input_valid_y, valid_lengths = single_batch_padding([valid_features[i]], \n",
    "                                                                               [valid_y[i]],\n",
    "                                                                               test=True)\n",
    "            output = model(input_valid_X.cuda(),valid_lengths)\n",
    "            output_label = torch.argmax(output,1).cpu().data\n",
    "            same_difference.append((output_label == input_valid_y).numpy())\n",
    "        accuracy = np.mean(same_difference)\n",
    "        print(\"validation accuracy: \",accuracy)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"../models/RNN_FC_model.pkt\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先加 hidden dimension\n",
    "# 加 fc layer\n",
    "# 加 dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
